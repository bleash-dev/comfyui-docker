name: Build and Deploy ComfyUI AMI

on:
  workflow_dispatch:

env:
  AWS_REGION: us-east-1

jobs:
  create-ami:
    runs-on: ubuntu-latest
    environment: "prod"
    if: github.event_name != 'pull_request'

    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Configure AWS credentials via OIDC
      uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: ${{ secrets.GH_ROLE_ARN }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get base AMI (Existing ComfyUI or Fresh Ubuntu)
      id: base-ami
      run: |
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        
        echo "üîç Looking for existing ComfyUI AMI to use as base..."
        
        # Try to get the latest ComfyUI AMI for this environment
        EXISTING_COMFYUI_AMI=$(aws ssm get-parameter \
          --name "/comfyui/ami/$ENVIRONMENT/latest" \
          --region ${{ env.AWS_REGION }} \
          --query 'Parameter.Value' \
          --output text 2>/dev/null || echo "")
        
        if [ -n "$EXISTING_COMFYUI_AMI" ] && [ "$EXISTING_COMFYUI_AMI" != "None" ]; then
          # Verify the AMI still exists and is available
          AMI_STATE=$(aws ec2 describe-images \
            --image-ids "$EXISTING_COMFYUI_AMI" \
            --region ${{ env.AWS_REGION }} \
            --query 'Images[0].State' \
            --output text 2>/dev/null || echo "not-found")
          
          if [ "$AMI_STATE" = "available" ]; then
            echo "üöÄ Found existing ComfyUI AMI: $EXISTING_COMFYUI_AMI"
            echo "‚úÖ Using existing ComfyUI AMI as base for faster incremental builds"
            
            # Get AMI details
            aws ec2 describe-images \
              --image-ids "$EXISTING_COMFYUI_AMI" \
              --query 'Images[0].[Name,Description,CreationDate]' \
              --output table \
              --region ${{ env.AWS_REGION }}
            
            echo "ami-id=$EXISTING_COMFYUI_AMI" >> $GITHUB_OUTPUT
            echo "ami-type=existing-comfyui" >> $GITHUB_OUTPUT
            
            # Get creation date for logging
            AMI_AGE=$(aws ec2 describe-images \
              --image-ids "$EXISTING_COMFYUI_AMI" \
              --query 'Images[0].CreationDate' \
              --output text \
              --region ${{ env.AWS_REGION }})
            echo "üìÖ Base AMI created: $AMI_AGE"
            echo "‚ö° This will be a much faster incremental build!"
            
          else
            echo "‚ö†Ô∏è Existing ComfyUI AMI found but not available (state: $AMI_STATE)"
            echo "üîÑ Falling back to fresh Ubuntu base"
            EXISTING_COMFYUI_AMI=""
          fi
        else
          echo "‚ÑπÔ∏è No existing ComfyUI AMI found in SSM Parameter Store"
          echo "üîÑ This will be a fresh installation"
        fi
        
        # Fallback to Ubuntu base if no existing ComfyUI AMI
        if [ -z "$EXISTING_COMFYUI_AMI" ]; then
          echo "üÜï Using fresh Ubuntu base for initial AMI creation"
          
          # Get latest Ubuntu 22.04 LTS AMI
          UBUNTU_AMI=$(aws ec2 describe-images \
            --owners 099720109477 \
            --filters "Name=name,Values=ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*" \
                "Name=state,Values=available" \
            --query "Images | sort_by(@, &CreationDate) | [-1].ImageId" \
            --output text \
            --region ${{ env.AWS_REGION }})
          
          echo "üñ•Ô∏è Using base Ubuntu AMI: $UBUNTU_AMI"
          echo "ami-id=$UBUNTU_AMI" >> $GITHUB_OUTPUT
          echo "ami-type=ubuntu" >> $GITHUB_OUTPUT
          
          # Get Ubuntu AMI details for reference
          aws ec2 describe-images \
            --image-ids $UBUNTU_AMI \
            --query 'Images[0].[Name,Description,CreationDate]' \
            --output table \
            --region ${{ env.AWS_REGION }}
        fi

    - name: Upload scripts to S3
      run: |
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        S3_PREFIX="s3://viral-comm-api-ec2-deployments-dev/comfyui-ami/${ENVIRONMENT}"
        
        echo "üì§ Uploading all scripts to S3..."
        echo "S3 path: ${S3_PREFIX}"
        
        # Simple sync of entire scripts directory
        echo "üîÑ Syncing entire scripts directory to S3..."
        aws s3 sync scripts/ "${S3_PREFIX}/" --region ${{ env.AWS_REGION }} --delete
        
        # Verify uploads by listing what was uploaded
        echo "üîç Verifying uploads..."
        echo "Scripts uploaded to S3:"
        aws s3 ls "${S3_PREFIX}/" --recursive --human-readable --summarize --region ${{ env.AWS_REGION }}
        
        echo "‚úÖ All scripts uploaded to S3 successfully"
        echo "s3-prefix=${S3_PREFIX}" >> $GITHUB_OUTPUT

    - name: Launch EC2 instance for AMI creation
      id: launch-instance
      timeout-minutes: 5
      run: |
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        INSTANCE_NAME="comfyui-ami-builder-${ENVIRONMENT}-$(date +%Y%m%d-%H%M%S)"
        
        echo "üöÄ Launching EC2 instance for AMI creation..."
        echo "Environment: $ENVIRONMENT"
        echo "Instance name: $INSTANCE_NAME"
        
        # Create user data script
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        S3_PREFIX="s3://viral-comm-api-ec2-deployments-dev/comfyui-ami/${ENVIRONMENT}"
        BASE_AMI_TYPE="${{ steps.base-ami.outputs.ami-type }}"
        BUILD_TYPE="${{ steps.base-ami.outputs.build-type }}"
        
        cat > user-data.sh << EOF
        #!/bin/bash
        set -e
        
        # Set environment variables
        export DEBIAN_FRONTEND=noninteractive
        export ENVIRONMENT="$ENVIRONMENT"
        export S3_PREFIX="$S3_PREFIX"
        
        # Log everything
        exec > >(tee /var/log/user-data.log) 2>&1
        echo "üöÄ Starting ComfyUI AMI setup at \$(date)"
        echo "Environment: \$ENVIRONMENT"
        echo "S3 Prefix: \$S3_PREFIX"
        echo "SETUP_STARTING" > /tmp/ami_progress.txt
        
        # Update system and install minimal requirements
        apt-get update -y
        apt-get install -y awscli
        
        # Download all scripts from S3
        echo "üì• Downloading scripts from S3..."
        mkdir -p /scripts
        cd /scripts
        aws s3 sync "\${S3_PREFIX}/" . --region ${{ env.AWS_REGION }}
        chmod +x *.sh 2>/dev/null || true
        chmod +x *.py 2>/dev/null || true
        
        # Run prepare_ami.sh which handles everything else
        echo "ÔøΩ Running prepare_ami.sh..."
        echo "RUNNING_PREPARE_AMI" > /tmp/ami_progress.txt
        timeout 3600 /scripts/prepare_ami.sh || {
            echo "‚ùå prepare_ami.sh failed with exit code: \$?"
            echo "Last checkpoint: \$(cat /tmp/ami_progress.txt 2>/dev/null || echo 'UNKNOWN')"
            exit 1
        }
        
        # Signal completion
        echo "AMI_SETUP_COMPLETE" > /tmp/ami_ready.txt
        echo "‚úÖ AMI setup completed at \$(date)"
        EOF
        
        # Get VPC and subnet with specific preference
        echo "üîç Finding VPC and subnet (preferred: viral-comm-api-proxy-vpc-dev)..."
        
        # Try to find the specific VPC first
        PREFERRED_VPC_NAME="viral-comm-api-viral-community-stack-dev/viral-comm-api-common-networking-dev/viral-comm-api-proxy-vpc-dev"
        PREFERRED_SUBNET_NAME="*vpc-proxy-subnetSubnet1*"
        PREFERRED_SUBNET_LOGICAL_ID="vpc-proxy-subnetSubnet1"
        
        echo "üéØ Looking for preferred VPC: $PREFERRED_VPC_NAME"
        
        # Try to find VPC by Name tag (CDK-managed resources usually have Name tags)
        VPC_ID=$(aws ec2 describe-vpcs \
          --filters "Name=tag:Name,Values=$PREFERRED_VPC_NAME" \
          --query 'Vpcs[0].VpcId' \
          --output text \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        
        # Also try shorter name patterns in case the full path isn't used
        if [[ -z "$VPC_ID" || "$VPC_ID" == "None" ]]; then
          echo "üîç Trying shorter VPC name pattern: *proxy-vpc-dev"
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=*proxy-vpc-dev" \
            --query 'Vpcs[0].VpcId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        fi
        
        # Fallback to default VPC
        if [[ -z "$VPC_ID" || "$VPC_ID" == "None" ]]; then
          echo "‚ö†Ô∏è Preferred VPC not found, trying default VPC..."
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=is-default,Values=true" \
            --query 'Vpcs[0].VpcId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        fi
        
        # Final fallback to any available VPC
        if [[ -z "$VPC_ID" || "$VPC_ID" == "None" ]]; then
          echo "‚ö†Ô∏è No default VPC found, using any available VPC..."
          VPC_ID=$(aws ec2 describe-vpcs \
            --query 'Vpcs[0].VpcId' \
            --output text \
            --region ${{ env.AWS_REGION }})
        fi
        
        echo "‚úÖ Selected VPC: $VPC_ID"
        
        # Now find the subnet - try preferred subnet first
        if [[ "$VPC_ID" != "None" && -n "$VPC_ID" ]]; then
          echo "üéØ Looking for preferred subnet: vpc-proxy-subnetSubnet1"
          
          SUBNET_ID=$(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=${VPC_ID}" "Name=tag:Name,Values=$PREFERRED_SUBNET_NAME" \
            --query 'Subnets[0].SubnetId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          
          # Try CDK logical ID pattern
          if [[ -z "$SUBNET_ID" || "$SUBNET_ID" == "None" ]]; then
            echo "üîç Trying CDK logical ID pattern: *vpc-proxy-subnetSubnet1*"
            SUBNET_ID=$(aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=${VPC_ID}" "Name=tag:aws:cloudformation:logical-id,Values=*vpc-proxy-subnetSubnet1*" \
              --query 'Subnets[0].SubnetId' \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          fi
          
          # Try looking for any SubnetSubnet1 pattern
          if [[ -z "$SUBNET_ID" || "$SUBNET_ID" == "None" ]]; then
            echo "üîç Trying generic SubnetSubnet1 pattern: *SubnetSubnet1*"
            SUBNET_ID=$(aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=${VPC_ID}" "Name=tag:Name,Values=*SubnetSubnet1*" \
              --query 'Subnets[0].SubnetId' \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          fi
          
          # Fallback to any public subnet in the VPC
          if [[ -z "$SUBNET_ID" || "$SUBNET_ID" == "None" ]]; then
            echo "‚ö†Ô∏è Preferred subnet not found, looking for any public subnet in VPC..."
            SUBNET_ID=$(aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=${VPC_ID}" "Name=map-public-ip-on-launch,Values=true" \
              --query 'Subnets[0].SubnetId' \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          fi
          
          # Final fallback to any subnet in the VPC
          if [[ -z "$SUBNET_ID" || "$SUBNET_ID" == "None" ]]; then
            echo "‚ö†Ô∏è No public subnet found, using any available subnet in VPC..."
            SUBNET_ID=$(aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=${VPC_ID}" \
              --query 'Subnets[0].SubnetId' \
              --output text \
              --region ${{ env.AWS_REGION }})
          fi
        fi
        
        echo "‚úÖ Selected Subnet: $SUBNET_ID"
        
        # Verify we have valid VPC and subnet
        if [[ -z "$VPC_ID" || "$VPC_ID" == "None" || -z "$SUBNET_ID" || "$SUBNET_ID" == "None" ]]; then
          echo "‚ùå Could not find valid VPC and subnet combination"
          echo "VPC_ID: $VPC_ID"
          echo "SUBNET_ID: $SUBNET_ID"
          exit 1
        fi
        
        # Get VPC and subnet names for better logging
        VPC_NAME=$(aws ec2 describe-vpcs \
          --vpc-ids "$VPC_ID" \
          --query 'Vpcs[0].Tags[?Key==`Name`].Value' \
          --output text \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "No name tag")
        
        SUBNET_NAME=$(aws ec2 describe-subnets \
          --subnet-ids "$SUBNET_ID" \
          --query 'Subnets[0].Tags[?Key==`Name`].Value' \
          --output text \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "No name tag")
        
        # Log what we're using with better details
        echo "üìã Network Configuration Summary:"
        echo "   VPC ID: $VPC_ID (Name: $VPC_NAME)"
        echo "   Subnet ID: $SUBNET_ID (Name: $SUBNET_NAME)"
        
        # Check if we got our preferred resources
        if [[ "$VPC_NAME" == *"viral-comm-api-proxy-vpc-dev"* ]]; then
          echo "üéâ Successfully using preferred viral-comm-api VPC!"
        else
          echo "‚ö†Ô∏è Using fallback VPC - preferred VPC not found"
        fi
        
        if [[ "$SUBNET_NAME" == *"vpc-proxy-subnetSubnet1"* ]]; then
          echo "üéâ Successfully using preferred subnet!"
        else
          echo "‚ö†Ô∏è Using fallback subnet - preferred subnet not found"
        fi
        
        # Create IAM role for EC2 instance to access S3
        echo "üîê Creating IAM role for EC2 instance..."
        ROLE_NAME="comfyui-ami-builder-role-$(date +%s)"
        
        # Create trust policy
        cat > trust-policy.json << 'TRUST_EOF'
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Allow",
              "Principal": {
                "Service": "ec2.amazonaws.com"
              },
              "Action": "sts:AssumeRole"
            }
          ]
        }
        TRUST_EOF
        
        # Create IAM role
        aws iam create-role \
          --role-name "$ROLE_NAME" \
          --assume-role-policy-document file://trust-policy.json \
          --region ${{ env.AWS_REGION }}
        
        # Attach S3 read-only policy
        aws iam attach-role-policy \
          --role-name "$ROLE_NAME" \
          --policy-arn "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess" \
          --region ${{ env.AWS_REGION }}
        
        # Attach SSM policy for status checking
        aws iam attach-role-policy \
          --role-name "$ROLE_NAME" \
          --policy-arn "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore" \
          --region ${{ env.AWS_REGION }}
        
        # Attach CloudWatch logs policy for debugging
        aws iam attach-role-policy \
          --role-name "$ROLE_NAME" \
          --policy-arn "arn:aws:iam::aws:policy/CloudWatchLogsFullAccess" \
          --region ${{ env.AWS_REGION }}
        
        # Create instance profile
        aws iam create-instance-profile \
          --instance-profile-name "$ROLE_NAME" \
          --region ${{ env.AWS_REGION }}
        
        # Add role to instance profile
        aws iam add-role-to-instance-profile \
          --instance-profile-name "$ROLE_NAME" \
          --role-name "$ROLE_NAME" \
          --region ${{ env.AWS_REGION }}
        
        # Wait a moment for IAM to propagate
        sleep 15
        
        echo "‚úÖ IAM role created: $ROLE_NAME"
        
        # Find security group - prefer CDK-managed security group from viral-comm-api stack
        echo "üîí Finding security group (preferred: viral-comm-api proxy security group)..."
        
        PREFERRED_SG_NAME="viral-comm-api-proxy-security-dev"
        
        # Try to find the CDK-managed security group first
        SG_ID=$(aws ec2 describe-security-groups \
          --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=$PREFERRED_SG_NAME" \
          --query 'SecurityGroups[0].GroupId' \
          --output text \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        
        # Try shorter patterns for the security group
        if [[ -z "$SG_ID" || "$SG_ID" == "None" ]]; then
          echo "üîç Trying shorter security group name pattern: *proxy-security*"
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=*proxy-security*" \
            --query 'SecurityGroups[0].GroupId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        fi
        
        # Try group name instead of tag
        if [[ -z "$SG_ID" || "$SG_ID" == "None" ]]; then
          echo "üîç Trying security group by group name: *proxy-security*"
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=group-name,Values=*proxy-security*" \
            --query 'SecurityGroups[0].GroupId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        fi
        
        # Fallback to default security group
        if [[ -z "$SG_ID" || "$SG_ID" == "None" ]]; then
          echo "‚ö†Ô∏è Preferred security group not found, using default security group..."
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text \
            --region ${{ env.AWS_REGION }})
        fi
        
        echo "‚úÖ Selected Security Group: $SG_ID"
        
        # Log what security group we're using and its rules
        SG_NAME=$(aws ec2 describe-security-groups \
          --group-ids "$SG_ID" \
          --query 'SecurityGroups[0].GroupName' \
          --output text \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "unknown")
        
        if [[ "$SG_NAME" == *"proxy-security"* ]]; then
          echo "üéâ Using viral-comm-api proxy security group with proper ComfyUI ports"
        else
          echo "‚ö†Ô∏è Using fallback security group: $SG_NAME"
          echo "‚ö†Ô∏è Note: This may not have the required ports open for ComfyUI access"
        fi
        
        # Display security group rules for debugging
        echo "üìã Security Group Rules:"
        aws ec2 describe-security-groups \
          --group-ids "$SG_ID" \
          --query 'SecurityGroups[0].IpPermissions[*].[IpProtocol,FromPort,ToPort,IpRanges[*].CidrIp]' \
          --output table \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "Could not retrieve security group rules"
        
        # Launch instance with VPC configuration, IAM role, and 20GB EBS volume
        INSTANCE_ID=$(aws ec2 run-instances \
          --image-id ${{ steps.base-ami.outputs.ami-id }} \
          --instance-type c5d.large \
          --subnet-id $SUBNET_ID \
          --associate-public-ip-address \
          --iam-instance-profile Name="$ROLE_NAME" \
          --user-data file://user-data.sh \
          --block-device-mappings '[{"DeviceName":"/dev/sda1","Ebs":{"VolumeSize":20,"VolumeType":"gp3","DeleteOnTermination":true}}]' \
          --region ${{ env.AWS_REGION }} \
          --tag-specifications "ResourceType=instance,Tags=[{Key=Name,Value=${INSTANCE_NAME}},{Key=Environment,Value=${ENVIRONMENT}},{Key=Purpose,Value=AMI-Builder},{Key=AutoTerminate,Value=true},{Key=IAMRole,Value=${ROLE_NAME}}]" \
          --query 'Instances[0].InstanceId' \
          --output text)
        
        echo "instance-id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        echo "iam-role=$ROLE_NAME" >> $GITHUB_OUTPUT
        
        # Get the public IP for network testing
        PUBLIC_IP=$(aws ec2 describe-instances \
          --instance-ids $INSTANCE_ID \
          --region ${{ env.AWS_REGION }} \
          --query 'Reservations[0].Instances[0].PublicIpAddress' \
          --output text)
        
        echo "public-ip=$PUBLIC_IP" >> $GITHUB_OUTPUT
        echo "üöÄ Launched instance: $INSTANCE_ID"
        echo "üåê Public IP: $PUBLIC_IP"
        echo "‚ö†Ô∏è Instance will be automatically terminated after AMI creation"
        echo "üí° Using VPC: $VPC_ID, Subnet: $SUBNET_ID, IAM Role: $ROLE_NAME"

    - name: Wait for instance setup completion
      timeout-minutes: 20
      run: |
        INSTANCE_ID="${{ steps.launch-instance.outputs.instance-id }}"
        echo "‚è≥ Waiting for instance setup to complete..."
        
        # Wait for instance to be running
        echo "üîÑ Waiting for instance to be running..."
        aws ec2 wait instance-running --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }}
        echo "‚úÖ Instance is running"
        
        # Wait for SSM agent to be ready
        echo "üîÑ Waiting for SSM agent to be ready..."
        for i in {1..10}; do
          if aws ssm describe-instance-information \
            --filters "Key=InstanceIds,Values=$INSTANCE_ID" \
            --region ${{ env.AWS_REGION }} \
            --query 'InstanceInformationList[0].PingStatus' \
            --output text 2>/dev/null | grep -q "Online"; then
            echo "‚úÖ SSM agent is online"
            break
          fi
          echo "‚è≥ SSM agent not ready yet, waiting... (attempt $i/10)"
          sleep 30
        done

    - name: Wait for AMI update completion
      timeout-minutes: 30
      run: |
        INSTANCE_ID="${{ steps.launch-instance.outputs.instance-id }}"
        AMI_TYPE="${{ steps.base-ami.outputs.ami-type }}"
        
        MAX_ATTEMPTS=50  # Fresh builds take longer  
        
        echo "Max attempts: $MAX_ATTEMPTS"
        
        for i in $(seq 1 $MAX_ATTEMPTS); do
          echo "üîç Checking AMI update status... (attempt $i/$MAX_ATTEMPTS)"
          
          # Check current progress
          PROGRESS_CHECK_ID=$(aws ssm send-command \
            --instance-ids $INSTANCE_ID \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "echo === Progress Check ===",
              "if [ -f /tmp/ami_checkpoints.txt ]; then",
              "  echo ALL_CHECKPOINTS_COMPLETED:",
              "  cat /tmp/ami_checkpoints.txt | tr '\n' ',' | sed 's/,$//'",
              "else",
              "  echo ALL_CHECKPOINTS_COMPLETED: NONE",
              "fi",
              "if [ -f /tmp/ami_progress.txt ]; then",
              "  echo CURRENT_PROGRESS: $(cat /tmp/ami_progress.txt)",
              "else",
              "  echo CURRENT_PROGRESS: UNKNOWN",
              "fi",
              "echo === Completion Check ===",
              "if [ -f /tmp/ami_ready.txt ]; then",
              "  echo FILE_EXISTS: READY",
              "  echo FILE_CONTENT: $(cat /tmp/ami_ready.txt)",
              "else",
              "  echo FILE_EXISTS: NOT_READY",
              "fi",
              "echo === Process Check ===",
              "ps aux | grep -E \"prepare_ami|user-data\" | grep -v grep || echo NO_PROCESS_RUNNING",
              "echo === Error Check ===",
              "tail -10 /var/log/user-data.log 2>/dev/null | grep -i error || echo NO_RECENT_ERRORS"
            ]' \
            --region ${{ env.AWS_REGION }} \
            --query 'Command.CommandId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$PROGRESS_CHECK_ID" ]; then
            sleep 10
            
            RESULT=$(aws ssm get-command-invocation \
              --command-id $PROGRESS_CHECK_ID \
              --instance-id $INSTANCE_ID \
              --region ${{ env.AWS_REGION }} \
              --query 'StandardOutputContent' \
              --output text 2>/dev/null || echo "PENDING")
            
            echo "Progress Status:"
            echo "$RESULT"
            
            # Check for errors in the logs (excluding known non-fatal issues)
            if [[ "$RESULT" == *"ERROR:"* || "$RESULT" == *"FAILED"* || "$RESULT" == *"error:"* ]]; then
              # Filter out known non-fatal errors (CloudWatch log groups already existing)
              if [[ "$RESULT" == *"ResourceAlreadyExistsException"* && "$RESULT" == *"log group already exists"* ]]; then
                echo "‚ÑπÔ∏è Detected CloudWatch log group creation warnings (non-fatal)"
              else
                echo "‚ùå Detected actual errors in AMI update logs"
                echo "üîç Getting detailed error information..."
                
                # Get detailed logs immediately when error is detected
                ERROR_LOG_ID=$(aws ssm send-command \
                  --instance-ids $INSTANCE_ID \
                  --document-name "AWS-RunShellScript" \
                  --parameters 'commands=[
                    "echo === DETAILED ERROR INVESTIGATION ===",
                    "echo === User Data Log (last 100 lines) ===",
                    "tail -100 /var/log/user-data.log 2>/dev/null || echo No user-data log found",
                    "echo === AMI Preparation Log ===",
                    "tail -50 /var/log/ami-preparation.log 2>/dev/null || echo No AMI preparation log found",
                    "echo === CloudInit Output Log ===",
                    "tail -50 /var/log/cloud-init-output.log 2>/dev/null || echo No cloud-init-output log found",
                    "echo === Process Status ===",
                    "ps aux | grep -E \"prepare_ami|user-data\" || echo No relevant processes found",
                    "echo === Script Files Check ===",
                    "ls -la /scripts/ 2>/dev/null || echo Scripts directory not found",
                    "echo === Environment Variables (from user-data context) ===",
                    "env | grep -E \"COMFY|AMI|CUDA|NVIDIA\" || echo No relevant environment variables found",
                    "echo === System Status ===",
                    "df -h && echo && free -h"
                  ]' \
                  --region ${{ env.AWS_REGION }} \
                  --query 'Command.CommandId' \
                  --output text 2>/dev/null || echo "")
                
                if [ -n "$ERROR_LOG_ID" ]; then
                  sleep 10
                  ERROR_DETAILS=$(aws ssm get-command-invocation \
                    --command-id $ERROR_LOG_ID \
                    --instance-id $INSTANCE_ID \
                    --region ${{ env.AWS_REGION }} \
                    --query 'StandardOutputContent' \
                    --output text 2>/dev/null || echo "Could not retrieve error details")
                  
                  echo "=== DETAILED ERROR INFORMATION ==="
                  echo "$ERROR_DETAILS"
                  echo "================================="
                fi
                
                exit 1
              fi
            fi
            
            # Check for completion - either file exists (READY) or contains completion marker
            if [[ "$RESULT" == *"FILE_EXISTS: READY"* ]] || [[ "$RESULT" == *"AMI_SETUP_COMPLETE"* ]]; then
              echo "‚úÖ AMI update completed!"
              if [[ "$RESULT" == *"FILE_EXISTS: READY"* ]]; then
                echo "   ‚Üí Detected completion file exists"
              fi
              if [[ "$RESULT" == *"AMI_SETUP_COMPLETE"* ]]; then
                echo "   ‚Üí Detected completion marker in file content"
              fi
              break
            fi
            
            # Extract current progress for better monitoring
            if [[ "$RESULT" == *"ALL_CHECKPOINTS_COMPLETED:"* ]]; then
              ALL_CHECKPOINTS=$(echo "$RESULT" | grep "ALL_CHECKPOINTS_COMPLETED:" | cut -d: -f2 | xargs)
              echo "üèÅ All completed checkpoints: $ALL_CHECKPOINTS"
            fi
            
            if [[ "$RESULT" == *"CURRENT_PROGRESS:"* ]]; then
              CURRENT_STEP=$(echo "$RESULT" | grep "CURRENT_PROGRESS:" | cut -d: -f2 | xargs)
              echo "üìç Current step: $CURRENT_STEP"
              
              # Provide context for different steps
              case "$CURRENT_STEP" in
                "SETUP_STARTING")
                  echo "   ‚Üí Starting AMI setup process"
                  ;;
                "RUNNING_PREPARE_AMI")
                  echo "   ‚Üí Running prepare_ami.sh (this may take several minutes)"
                  ;;
                "SCRIPTS_DOWNLOADED_AND_VALIDATED")
                  echo "   ‚Üí Scripts downloaded from S3 and validated successfully"
                  ;;
                "SCRIPTS_SETUP")
                  echo "   ‚Üí Setting up system scripts and configurations"
                  ;;
                "CLOUDWATCH_CONFIGURED"|"CLOUDWATCH_CONFIGURED_WITH_WARNINGS")
                  echo "   ‚Üí CloudWatch logging configured (log group warnings are normal)"
                  ;;
                "CLOUDWATCH_SKIPPED")
                  echo "   ‚Üí CloudWatch setup skipped"
                  ;;
                "VALIDATION_COMPLETE")
                  echo "   ‚Üí Final validation completed - AMI is ready"
                  ;;
                "AMI_SETUP_COMPLETE")
                  echo "   ‚Üí AMI setup completed successfully"
                  ;;
                *)
                  echo "   ‚Üí Step: $CURRENT_STEP"
                  ;;
              esac
            fi
            
            # Check if process is still running
            if [[ "$RESULT" == *"NO_PROCESS_RUNNING"* ]]; then
              echo "‚ö†Ô∏è AMI update process is not running - may have completed or failed"
              echo "üîç Getting detailed logs for debugging..."
            fi
          fi
          
          if [ $i -eq $MAX_ATTEMPTS ]; then
            echo "‚ùå Timeout waiting for AMI update"
            echo "üîç Checking instance logs for debugging..."
            
            # Get last 50 lines of user-data log
            LOG_COMMAND_ID=$(aws ssm send-command \
              --instance-ids $INSTANCE_ID \
              --document-name "AWS-RunShellScript" \
              --parameters 'commands=["tail -50 /var/log/user-data.log || echo No user-data log found"]' \
              --region ${{ env.AWS_REGION }} \
              --query 'Command.CommandId' \
              --output text 2>/dev/null || echo "")
            
            if [ -n "$LOG_COMMAND_ID" ]; then
              sleep 10
              aws ssm get-command-invocation \
                --command-id $LOG_COMMAND_ID \
                --instance-id $INSTANCE_ID \
                --region ${{ env.AWS_REGION }} \
                --query 'StandardOutputContent' \
                --output text 2>/dev/null || echo "Could not retrieve logs"
            fi
            
            exit 1
          fi
          
          sleep 15
        done

    - name: Verify ComfyUI setup
      timeout-minutes: 5
      run: |
        INSTANCE_ID="${{ steps.launch-instance.outputs.instance-id }}"
        echo "üîç Verifying ComfyUI setup via health endpoint..."
        
        # Test the health endpoint (service should already be running from prepare_ami.sh)
        echo "üè• Testing health endpoint..."
        HEALTH_CHECK_ID=$(aws ssm send-command \
          --instance-ids $INSTANCE_ID \
          --document-name "AWS-RunShellScript" \
          --parameters 'commands=[
            "echo Testing health endpoint...",
            "# Check if service is running",
            "SERVICE_STATUS=$(systemctl is-active comfyui-multitenant.service 2>/dev/null || echo \"inactive\")",
            "echo \"Service status: $SERVICE_STATUS\"",
            "# If service is in activating state, wait a bit and check again",
            "if [ \"$SERVICE_STATUS\" = \"activating\" ]; then",
            "  echo \"Service is activating, waiting 10 seconds...\"",
            "  sleep 10",
            "  SERVICE_STATUS=$(systemctl is-active comfyui-multitenant.service 2>/dev/null || echo \"inactive\")",
            "  echo \"Service status after wait: $SERVICE_STATUS\"",
            "fi",
            "# Check service logs if not active",
            "if [ \"$SERVICE_STATUS\" != \"active\" ]; then",
            "  echo \"Service not active, checking logs...\"",
            "  journalctl -u comfyui-multitenant.service --no-pager -n 20 || echo \"No service logs\"",
            "  echo \"Checking what is using port 80...\"",
            "  netstat -tlnp | grep :80 || echo \"Nothing listening on port 80\"",
            "  echo \"Checking if tenant manager process is running...\"",
            "  ps aux | grep tenant_manager | grep -v grep || echo \"No tenant_manager process found\"",
            "fi",
            "# Test health endpoint",
            "HEALTH_RESPONSE=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost/health 2>/dev/null || echo \"CURL_FAILED\")",
            "echo \"Health endpoint HTTP status: $HEALTH_RESPONSE\"",
            "if [ \"$HEALTH_RESPONSE\" = \"200\" ]; then",
            "  echo \"HEALTH_CHECK: SUCCESS\"",
            "  # Get the actual response body",
            "  curl -s http://localhost/health 2>/dev/null || echo \"Could not get response body\"",
            "else",
            "  echo \"HEALTH_CHECK: FAILED\"",
            "  echo \"Debugging information:\"",
            "  echo \"Service status: $SERVICE_STATUS\"",
            "  # Check if port is listening",
            "  netstat -tlnp | grep :80 || echo \"Port 80 not listening\"",
            "  # Check recent logs",
            "  journalctl -u comfyui-multitenant.service --no-pager -n 20 || echo \"No service logs\"",
            "fi"
          ]' \
          --region ${{ env.AWS_REGION }} \
          --query 'Command.CommandId' \
          --output text)
        
        sleep 10
        HEALTH_RESULT=$(aws ssm get-command-invocation \
          --command-id $HEALTH_CHECK_ID \
          --instance-id $INSTANCE_ID \
          --region ${{ env.AWS_REGION }} \
          --query 'StandardOutputContent' \
          --output text)
        
        echo "Health check result:"
        echo "$HEALTH_RESULT"
        
        # Check if health endpoint responded successfully
        if [[ "$HEALTH_RESULT" == *"HEALTH_CHECK: SUCCESS"* ]]; then
          echo "‚úÖ Health endpoint test passed - ComfyUI system is working!"
          echo "üéâ Service was already running from AMI preparation - no need to manage it manually"
        else
          echo "‚ùå Health endpoint test failed - ComfyUI system is not working properly"
          
          # Get additional debugging info only on failure
          echo "üîç Getting debugging information..."
          DEBUG_ID=$(aws ssm send-command \
            --instance-ids $INSTANCE_ID \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "echo === System Debugging ===",
              "echo \"Tenant manager file:\"",
              "ls -la /usr/local/bin/tenant_manager.py 2>/dev/null || echo \"File not found\"",
              "echo \"Python version:\"",
              "python3 --version 2>/dev/null || echo \"Python not found\"",
              "echo \"Service logs (last 30 lines):\"",
              "journalctl -u comfyui-multitenant.service --no-pager -n 30 2>/dev/null || echo \"No service logs\"",
              "echo \"AMI preparation log (last 20 lines):\"",
              "tail -20 /var/log/ami-preparation.log 2>/dev/null || echo \"No AMI prep log\""
            ]' \
            --region ${{ env.AWS_REGION }} \
            --query 'Command.CommandId' \
            --output text)
          
          sleep 10
          DEBUG_INFO=$(aws ssm get-command-invocation \
            --command-id $DEBUG_ID \
            --instance-id $INSTANCE_ID \
            --region ${{ env.AWS_REGION }} \
            --query 'StandardOutputContent' \
            --output text)
          
          echo "Debug Information:"
          echo "$DEBUG_INFO"
          
          exit 1
        fi
        
        echo "üéâ ComfyUI verification complete - AMI is ready for creation!"

    - name: Create or update AMI
      id: create-ami
      timeout-minutes: 10
      run: |
        INSTANCE_ID="${{ steps.launch-instance.outputs.instance-id }}"
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        
        # Use consistent AMI naming (no timestamp for updates)
        AMI_NAME="comfyui-multitenant-${ENVIRONMENT}"
        
        echo "üì∏ Creating fresh AMI from instance: $INSTANCE_ID"
        echo "üè∑Ô∏è AMI name: $AMI_NAME"
        
        # Validate that the system is ready for AMI creation
        echo "‚úÖ System validated and ready for AMI creation"
        
        # Check for any existing AMI with the same name and deregister it
        EXISTING_AMI_WITH_NAME=$(aws ec2 describe-images \
          --owners self \
          --filters "Name=name,Values=$AMI_NAME" \
          --query 'Images[0].ImageId' \
          --output text \
          --region ${{ env.AWS_REGION }} 2>/dev/null || echo "None")
        
        # Always fresh setup, but check for existing AMI with same name to replace
        if [ -n "$EXISTING_AMI_WITH_NAME" ] && [ "$EXISTING_AMI_WITH_NAME" != "None" ]; then
          OLD_AMI_ID="$EXISTING_AMI_WITH_NAME"
          echo "üóëÔ∏è Found existing AMI with same name, will replace: $OLD_AMI_ID"
        else
          OLD_AMI_ID=""
          echo "üÜï Creating fresh AMI (no existing AMI found)"
        fi
        
        # Get snapshots for cleanup if we have an old AMI to replace
        if [ -n "$OLD_AMI_ID" ] && [ "$OLD_AMI_ID" != "None" ]; then
          OLD_SNAPSHOTS=$(aws ec2 describe-images \
            --image-ids $OLD_AMI_ID \
            --query 'Images[0].BlockDeviceMappings[*].Ebs.SnapshotId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          
          echo "üìã Old AMI to replace: $OLD_AMI_ID"
          echo "üìã Old AMI snapshots to clean up: $OLD_SNAPSHOTS"
          
          # Deregister the old AMI BEFORE creating the new one to avoid name conflict
          echo "üóëÔ∏è Deregistering old AMI to avoid name conflict..."
          aws ec2 deregister-image --image-id $OLD_AMI_ID --region ${{ env.AWS_REGION }} || {
            echo "‚ö†Ô∏è Failed to deregister old AMI, continuing anyway..."
          }
          
          # Wait a moment for deregistration to propagate
          sleep 5
        else
          OLD_SNAPSHOTS=""
        fi
        
        # Stop the instance before creating AMI
        aws ec2 stop-instances --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }}
        aws ec2 wait instance-stopped --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }}
        
        # Create new AMI with consistent naming
        NEW_AMI_ID=$(aws ec2 create-image \
          --instance-id $INSTANCE_ID \
          --name "$AMI_NAME" \
          --description "ComfyUI Multi-Tenant AMI for $ENVIRONMENT environment (Docker-Free) - updated $(date +%Y-%m-%d)" \
          --region ${{ env.AWS_REGION }} \
          --tag-specifications 'ResourceType=image,Tags=[{Key=Name,Value='"$AMI_NAME"'},{Key=Environment,Value='"$ENVIRONMENT"'},{Key=DeploymentType,Value="Docker-Free"},{Key=Branch,Value=${{ github.ref_name }}},{Key=LastUpdated,Value='$(date -u +"%Y-%m-%dT%H:%M:%SZ")'}]' \
          --query 'ImageId' \
          --output text)
        
        echo "ami-id=$NEW_AMI_ID" >> $GITHUB_OUTPUT
        echo "old-ami-id=${OLD_AMI_ID:-}" >> $GITHUB_OUTPUT
        echo "old-snapshots=${OLD_SNAPSHOTS:-}" >> $GITHUB_OUTPUT
        echo "‚úÖ New AMI created: $NEW_AMI_ID"
        
        if [ -n "$OLD_AMI_ID" ] && [ "$OLD_AMI_ID" != "None" ]; then
          echo "üîÑ This replaces the previous AMI: $OLD_AMI_ID"
        else
          echo "üÜï This is a fresh AMI creation"
        fi

    - name: Wait for AMI to be available
      timeout-minutes: 60
      run: |
        AMI_ID="${{ steps.create-ami.outputs.ami-id }}"
        echo "‚è≥ Waiting for AMI to be available..."
        echo "   This can take 10-30 minutes depending on AMI size and AWS load"
        echo "   AMI ID: $AMI_ID"
        
        # Custom polling loop with longer timeout and progress reporting
        MAX_WAIT_TIME=3600  # 60 minutes in seconds
        CHECK_INTERVAL=30   # Check every 30 seconds
        ELAPSED_TIME=0
        
        while [ $ELAPSED_TIME -lt $MAX_WAIT_TIME ]; do
          # Get AMI state
          AMI_STATE=$(aws ec2 describe-images \
            --image-ids $AMI_ID \
            --query 'Images[0].State' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "unknown")
          
          # Get progress percentage if available
          AMI_PROGRESS=$(aws ec2 describe-images \
            --image-ids $AMI_ID \
            --query 'Images[0].StateReason.Message' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          
          # Calculate elapsed time in minutes for display
          ELAPSED_MINUTES=$((ELAPSED_TIME / 60))
          REMAINING_MINUTES=$(((MAX_WAIT_TIME - ELAPSED_TIME) / 60))
          
          echo "üïê Time elapsed: ${ELAPSED_MINUTES}m | Remaining: ${REMAINING_MINUTES}m | State: $AMI_STATE"
          
          # Show progress if available
          if [[ "$AMI_PROGRESS" == *"%"* ]]; then
            echo "   üìä Progress: $AMI_PROGRESS"
          elif [ -n "$AMI_PROGRESS" ] && [ "$AMI_PROGRESS" != "None" ]; then
            echo "   üìù Status: $AMI_PROGRESS"
          fi
          
          # Check if AMI is available
          case "$AMI_STATE" in
            "available")
              echo "‚úÖ AMI is available: $AMI_ID"
              echo "‚è±Ô∏è Total wait time: ${ELAPSED_MINUTES} minutes"
              
              # Get final AMI details
              echo "üìã Final AMI Details:"
              aws ec2 describe-images \
                --image-ids $AMI_ID \
                --query 'Images[0].[Name,Description,CreationDate,Architecture,VirtualizationType,RootDeviceType]' \
                --output table \
                --region ${{ env.AWS_REGION }}
              
              exit 0
              ;;
            "failed")
              echo "‚ùå AMI creation failed"
              echo "üîç Failure reason: $AMI_PROGRESS"
              
              # Get detailed failure information
              aws ec2 describe-images \
                --image-ids $AMI_ID \
                --query 'Images[0].[State,StateReason]' \
                --output table \
                --region ${{ env.AWS_REGION }}
              
              exit 1
              ;;
            "pending")
              echo "   ‚öôÔ∏è AMI creation in progress..."
              ;;
            "unknown")
              echo "   ‚ö†Ô∏è Could not determine AMI state (AWS API issue?)"
              ;;
            *)
              echo "   üìù AMI state: $AMI_STATE"
              ;;
          esac
          
          # Wait before next check
          sleep $CHECK_INTERVAL
          ELAPSED_TIME=$((ELAPSED_TIME + CHECK_INTERVAL))
          
          # Show progress indicators at different intervals
          if [ $((ELAPSED_TIME % 300)) -eq 0 ]; then  # Every 5 minutes
            echo "üí° AMI creation typically takes 10-30 minutes. Large AMIs or high AWS load can take longer."
            echo "   Current wait time: ${ELAPSED_MINUTES} minutes"
          fi
        done
        
        # Timeout reached
        echo "‚è∞ Timeout reached after $((MAX_WAIT_TIME / 60)) minutes"
        echo "‚ùå AMI creation is taking longer than expected"
        echo "üîç Current AMI state: $AMI_STATE"
        echo "üìù Last known progress: $AMI_PROGRESS"
        echo ""
        echo "üí° Possible reasons for long AMI creation:"
        echo "   ‚Ä¢ Large AMI size (ComfyUI with models can be several GB)"
        echo "   ‚Ä¢ High AWS load in the region"
        echo "   ‚Ä¢ Complex AMI with many files"
        echo ""
        echo "üîß You can check AMI status manually with:"
        echo "   aws ec2 describe-images --image-ids $AMI_ID --region ${{ env.AWS_REGION }}"
        echo ""
        echo "‚ö†Ô∏è The AMI creation process may still complete successfully."
        echo "   Check the AWS Console or run the command above to verify."
        
        exit 1

    - name: Clean up old AMI snapshots
      if: steps.create-ami.outputs.old-snapshots != ''
      run: |
        OLD_SNAPSHOTS="${{ steps.create-ami.outputs.old-snapshots }}"
        NEW_AMI_ID="${{ steps.create-ami.outputs.ami-id }}"
        OLD_AMI_ID="${{ steps.create-ami.outputs.old-ami-id }}"
        
        echo "üßπ Cleaning up old AMI snapshots now that new AMI is available..."
        echo "New AMI: $NEW_AMI_ID"
        echo "Old AMI (already deregistered): $OLD_AMI_ID"
        
        # Clean up old snapshots (AMI was already deregistered during creation)
        if [ -n "$OLD_SNAPSHOTS" ] && [ "$OLD_SNAPSHOTS" != "None" ] && [ "$OLD_SNAPSHOTS" != "" ]; then
          echo "üóëÔ∏è Cleaning up old snapshots: $OLD_SNAPSHOTS"
          for SNAPSHOT in $OLD_SNAPSHOTS; do
            if [ "$SNAPSHOT" != "None" ] && [ -n "$SNAPSHOT" ]; then
              echo "üóëÔ∏è Deleting snapshot: $SNAPSHOT"
              aws ec2 delete-snapshot --snapshot-id $SNAPSHOT --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è Failed to delete snapshot $SNAPSHOT"
            fi
          done
          
          echo "‚úÖ Old AMI snapshots cleaned up successfully"
        else
          echo "‚ÑπÔ∏è No old snapshots to clean up"
        fi

    - name: Store AMI details in SSM Parameter Store
      run: |
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        AMI_ID="${{ steps.create-ami.outputs.ami-id }}"
        CREATION_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        BRANCH_NAME="${{ github.ref_name }}"
        COMMIT_SHA="${{ github.sha }}"
        
        echo "üìù Storing AMI details in SSM Parameter Store..."
        echo "Environment: $ENVIRONMENT"
        echo "AMI ID: $AMI_ID"
        
        # Store the latest AMI ID
        aws ssm put-parameter \
          --name "/comfyui/ami/$ENVIRONMENT/latest" \
          --value "$AMI_ID" \
          --type "String" \
          --overwrite \
          --description "Latest ComfyUI AMI ID for $ENVIRONMENT environment" \
          --region ${{ env.AWS_REGION }}
        
        echo "‚úÖ Stored AMI ID in /comfyui/ami/$ENVIRONMENT/latest"
        
        # Store detailed metadata as JSON
        METADATA=$(cat << EOF
        {
          "ami_id": "$AMI_ID",
          "deployment_type": "direct-ami",
          "environment": "$ENVIRONMENT",
          "creation_date": "$CREATION_DATE",
          "branch": "$BRANCH_NAME",
          "commit_sha": "$COMMIT_SHA",
          "region": "${{ env.AWS_REGION }}",
          "workflow_run_id": "${{ github.run_id }}",
          "workflow_run_number": "${{ github.run_number }}"
        }
        EOF
        )
        
        aws ssm put-parameter \
          --name "/comfyui/ami/$ENVIRONMENT/metadata" \
          --value "$METADATA" \
          --type "String" \
          --overwrite \
          --description "Detailed metadata for latest ComfyUI AMI in $ENVIRONMENT environment" \
          --region ${{ env.AWS_REGION }}
        
        echo "‚úÖ Stored AMI metadata in /comfyui/ami/$ENVIRONMENT/metadata"
        
        # Also store a timestamped version for history
        aws ssm put-parameter \
          --name "/comfyui/ami/$ENVIRONMENT/history/$AMI_ID" \
          --value "$METADATA" \
          --type "String" \
          --description "Historical metadata for AMI $AMI_ID in $ENVIRONMENT environment" \
          --region ${{ env.AWS_REGION }}
        
        echo "‚úÖ Stored historical AMI metadata in /comfyui/ami/$ENVIRONMENT/history/$AMI_ID"
        
        echo ""
        echo "üìã SSM Parameter Store Summary:"
        echo "   Latest AMI ID: /comfyui/ami/$ENVIRONMENT/latest"
        echo "   Latest Metadata: /comfyui/ami/$ENVIRONMENT/metadata"
        echo "   Historical Record: /comfyui/ami/$ENVIRONMENT/history/$AMI_ID"
        echo ""
        echo "üí° Access in your code using AWS SDK:"
        echo "   aws ssm get-parameter --name '/comfyui/ami/$ENVIRONMENT/latest' --region ${{ env.AWS_REGION }}"

    - name: Cleanup resources
      if: always()
      run: |
        INSTANCE_ID="${{ steps.launch-instance.outputs.instance-id }}"
        
        if [ -n "$INSTANCE_ID" ]; then
          echo "üßπ Cleaning up instance: $INSTANCE_ID"
          aws ec2 terminate-instances --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è Failed to terminate instance"
          echo "‚úÖ Instance termination initiated"
        else
          echo "‚ÑπÔ∏è No instance to cleanup"
        fi

    - name: Display deployment summary
      run: |
        ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}"
        AMI_TYPE="${{ steps.base-ami.outputs.ami-type }}"
        OLD_AMI="${{ steps.create-ami.outputs.old-ami-id }}"
        
        echo ""
        echo "üéâ Deployment Summary"
        echo "===================="
        echo "Environment: $ENVIRONMENT"
        echo "AMI ID: ${{ steps.create-ami.outputs.ami-id }}"
        echo "Base AMI Type: $AMI_TYPE"
        echo "Instance ID: ${{ steps.launch-instance.outputs.instance-id }} (terminated)"
        echo "S3 Scripts: s3://viral-comm-api-ec2-deployments-dev/comfyui-ami/$ENVIRONMENT/"
        echo ""
        echo "üì¶ AMI Management:"
        if [ "$AMI_TYPE" = "existing-comfyui" ]; then
          echo "  üîÑ Used existing ComfyUI AMI as base (faster incremental build)"
          echo "  ‚ö° Build was much faster by reusing existing installation"
        else
          echo "  üÜï Created fresh AMI from Ubuntu base (Docker-Free)"
          echo "  ÔøΩ Next build will be faster using this as base"
        fi
        if [ -n "$OLD_AMI" ]; then
          echo "  üóëÔ∏è Replaced old AMI: $OLD_AMI"
        fi
        echo "  üêç Direct Python installation (no Docker overhead)"
        echo ""
        echo "üîó SSM Parameter Store:"
        echo "  üìç Latest AMI: /comfyui/ami/$ENVIRONMENT/latest"
        echo "  üìä Metadata: /comfyui/ami/$ENVIRONMENT/metadata"
        echo "  üìö History: /comfyui/ami/$ENVIRONMENT/history/${{ steps.create-ami.outputs.ami-id }}"
        echo ""
        echo "‚úÖ AMI is ready for deployment!"
        echo ""
        echo "üöÄ Next Steps:"
        echo "1. Retrieve AMI ID: aws ssm get-parameter --name '/comfyui/ami/$ENVIRONMENT/latest'"
        echo "2. Use the AMI ID to launch instances"
        echo "3. Tenant manager starts automatically as systemd service"
        echo "4. ComfyUI instances managed via HTTP API on port 80"
        echo "5. Custom nodes and models are pre-installed"
        echo ""
        echo "üí° Architecture Benefits:"
        echo "  ‚Ä¢ Multi-tenant ComfyUI instances (Docker-Free)"
        echo "  ‚Ä¢ HTTP API for tenant management"
        echo "  ‚Ä¢ Direct Python execution (better performance)"
        echo "  ‚Ä¢ Automatic scaling and resource management"
        echo "  ‚Ä¢ Systemd service management"
        echo "  ‚Ä¢ Incremental AMI builds for faster iterations"